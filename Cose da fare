-Plottare grafico: loss vs. n° epoch
-Chiedere alliegro il 0.5 a riga 58
-CD_Loss = cd_weight * ( 0.5 * AVG_Y2X + 0.5 * AVG_X2Y )

    Where 'cd_weight' is a loss weight term that you should cross-validate. Hint: try with cd_weight=100!

-Per i momenti di noia cambiare le grandezze all'interno della classe decoder
-Questione data training e data test e validation
-mettere una baseline con rumore a 0 e stessa nuvola di punti ad 1 (loss va 300 a 0)

CLASSI DA TESTARE:
Airplane, Chair, Table,
Lamp, Car, Motorbike, Mug

----------------------------------settimana 7 giugno
1. implementare printPointCloud con possibilità di rotazione
2. grid search su
    a. dimensione del codice (128, 512, 1024)
    b. learning rate (1e-3, 0.5e-3, 1e-4)
    c. gamma (0.25, 0.5)
    e. weight_decay (1e-3, 1e-4)
    f. dropout (0.5, 1)
    g. architettura (depper_autoencoder, original_autoencoder)
TRAIN CON UNA SOLA CLASSE: nepoch: 50
TRAIN CON TUTTO IL DATASET: nepoch: 100
3. validare gli hyperparametri utilizzando solo UNA CLASSE
4. svolgere il punto precedente due volte, con due classi distinte. Una difficile (chair), una semplice (airplane)
5. confronta gli hyperparametri ottenuti
6. utilizzare gli hyperparametri ottenuti ai punti precedenti (usa quelli ottenuti con la classe difficile)
    per trainare il MODELLO MIGLIORE.
    PROVA DIVERSI VALORI DI: size_encoder (2-3, anche più grandi di 1024)

-----------------------------------LOSS
indicare il fattore moltiplicativo usato per la loss (al fondo della tabella)... sulla relazione finale

-----------------------------------DOMANDE:
1. quale classe usare per fare cross validation? una qualsiasi oppure usiamo quella più complessa?
    come 'identificare la più complessa':
    eseguire training con 25 epoche e hyperparametri fissi
2. dropout: dove lo inseriamo? su tutti i layer del decoder? o solo su un paio?
3. scheduler: conviene usarlo? Quale sarebbe il 'migliore' nel nostro caso?
    usare sia gamma che stepSize come hyperparametri?
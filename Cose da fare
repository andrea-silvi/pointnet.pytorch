-Plottare grafico: loss vs. n° epoch
-Chiedere alliegro il 0.5 a riga 58
-CD_Loss = cd_weight * ( 0.5 * AVG_Y2X + 0.5 * AVG_X2Y )

    Where 'cd_weight' is a loss weight term that you should cross-validate. Hint: try with cd_weight=100!

-Per i momenti di noia cambiare le grandezze all'interno della classe decoder
-Questione data training e data test e validation
-mettere una baseline con rumore a 0 e stessa nuvola di punti ad 1 (loss va 300 a 0)

CLASSI DA TESTARE:
Airplane, Chair, Table,
Lamp, Car, Motorbike, Mug

# TODO - DA INSERIRE NEL REPORT:
1. nell'attachment del report, aggiungere motivazioni relative alla scelta del LEARNING RATE:
    mostrare tabella con risultati della grid search (con classe singola Lamp).
    Per semplicità, proietta i dati considerando SIZE_ENCODER e ARCHITECTURE prefissati (in modo da ridurre la
    quantità di dati in tabella)

----------------------------------settimana 7 giugno
1. implementare printPointCloud con possibilità di rotazione
2. grid search su
    a. dimensione del codice (128, 512, 1024)
    b. learning rate (1e-3, 0.5e-3, 1e-4)
    c. gamma (0.25, 0.5)
    e. weight_decay (1e-3, 1e-4)
    f. dropout (0.5, 1)
    g. architettura (deeper_autoencoder, original_autoencoder)
TRAIN CON UNA SOLA CLASSE: nepoch: 50
TRAIN CON TUTTO IL DATASET: nepoch: 100
3. validare gli hyperparametri utilizzando solo UNA CLASSE
4. svolgere il punto precedente due volte, con due classi distinte. Una difficile (chair), una semplice (airplane)
5. confronta gli hyperparametri ottenuti
6. utilizzare gli hyperparametri ottenuti ai punti precedenti (usa quelli ottenuti con la classe difficile)
    per trainare il MODELLO MIGLIORE.
    PROVA DIVERSI VALORI DI: size_encoder (2-3, anche più grandi di 1024)

-----------------------------------LOSS
indicare il fattore moltiplicativo usato per la loss (al fondo della tabella)... sulla relazione finale

-----------------------------------DOMANDE:
1. quale classe usare per fare cross validation? una qualsiasi oppure usiamo quella più complessa?
    come 'identificare la più complessa':
    eseguire training con 25 epoche e hyperparametri fissi
2. dropout: dove lo inseriamo? su tutti i layer del decoder? o solo su un paio?
3. scheduler: conviene usarlo? Quale sarebbe il 'migliore' nel nostro caso?
    usare sia gamma che stepSize come hyperparametri?
4. early stopping: dopo la 50esima epoca, prima che modello salvare? miglior validation loss o ultimo?

-----------------------------------RISPOSTE:
1. usa tutte le classi. COnsiderando solo alcuni parametri
2. non esagerare con il dropout. Non è necessario. In generale non c'è una regola fissa, ma conviene non
    inserirlo in ogni layer.
    Ulteriore consiglio: prendi spunto dal codice di pointnet o altri codici (esperimenti su point cloud)
3. se lr alto (1e-3) scheduler ogni 10 epoche, 0.5 gamma
    se lr basso (1e-4) scheduler non strettamente necessario
4.
5. pointnet 1, pointnet 2, pointnet 3: mostrare i risultati su singola classe e indicare quale performa meglio
    usare la migliore per i prossimi risultati
6. controlla codice GCNN, e fxia (point segmentation) per quanto riguarda le skip connections
7. LOSS (densità). Scarica dataset ShapeNetCore.v2: testa le densità su questo dataset
    guarda repulsion loss (weight: 0.001). Se pesi una loss con x, l'altra la pesi con 1-x (regola generale)
    https://github.com/AnTao97/PointCloudDatasets
    FARE SAMPLING WITHOUT REPLACEMENT!!! ALTRIMENTI IMPUTTANA TUTTO
8. l'encoder tra part segmentation e classification è diverso, da considerare durante l'eventuale implementazione.
    leggi: https://arxiv.org/pdf/2004.07392.pdf

https://github.com/yanx27/Pointnet_Pointnet2_pytorch

---------------------------------------sabato 12 giugno:
1. point cloud (15 per classe)
2. sistemare training finale (tutte le classi)
3. dare un'occhiata gcnn
4. skip connections??? eventualmente sarebbe la terza architettura. Non fondamentale. Da discutere